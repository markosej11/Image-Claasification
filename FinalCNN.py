# -*- coding: utf-8 -*-
"""test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-tvp_UAIlUgCyAAQnmGznrjbsN7mIPUm
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import os
import cv2
import random
import glob
import copy
import tqdm
from PIL import Image
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
from torchvision import transforms, datasets
import torchvision.utils as vutils
from torchsummary import summary
# %matplotlib inline
from google.colab import drive

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

drive.mount('/content/gdrive')

dataroot = '/content/gdrive/My Drive/train/'

batch_size = 32
# Number of GPUs available. Use 0 for CPU mode.

transform = transforms.Compose([transforms.Resize(image_size),
                                transforms.CenterCrop(image_size),
                                transforms.ToTensor(),
                                transforms.Normalize([0.485, 0.456, 0.406],
                                                    [0.229, 0.224, 0.225])])

dataset = datasets.ImageFolder(root=dataroot,transform=transform)

dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,
                                         shuffle=True, num_workers=workers)

# Decide which device we want to run on
device = torch.device("cuda:0" if (torch.cuda.is_available() and num_of_GPU > 0) else "cpu")

sample_data = next(iter(dataloader))
print("Shape of the images: {}".format(sample_data[0].shape))
print("Number of Input Images: {}".format(len(dataset)))

classes = ['cat','dog']
def view_sample_image(img):
    img = img / 2 + 0.5
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg,(1,2,0)))
    
sampledata = iter(dataloader)
images, labels = sampledata.next()

print("Shape of the images",images.shape)
print("Shape of the labels",labels.shape)

fig = plt.figure(figsize=(15,20))
for i in np.arange(4):
    ax = fig.add_subplot(1,4, i+1, xticks = [], yticks = [])
    view_sample_image(images[i])
    ax.set_title(classes[labels[i]])

def initialize_weights(w):
    classname = w.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(w.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(w.weight.data, 1.0, 0.02)
        nn.init.constant_(w.bias.data, 0)

number_of_channels = 3
size_latent_vector_z = 100
num_discriminator_features = 64
num_epochs = 1
learning_rate = 0.5
beta1 = 0.5

import torch.nn.functional as F
class Network(nn.Module):
    def __init__(self):
        super(Network, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 2)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

model = Network().to(device)
model.apply(initialize_weights)
summary(model, input_size=(3, 32, 32))

loss_fun = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=0.5)

print("Starting Training")
training_losses = []

for epoch in range(num_epochs):
    running_loss = 0.0
    for i, data in enumerate(dataloader,0):
        model.zero_grad()
        inputs,labels = data[0].to(device), data[1].to(device)
#         labels = data[1].to(device)
        
            # Forward pass
        outputs = model(inputs)
        loss = loss_fun(outputs, labels)
            # Backward and optimize
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()

        if i % 2000 == 1999:
            print ('[{}/{}][{}/{}]\t Training_loss: {:.3f}'
                   .format(epoch+1,num_epochs,i,len(dataloader),running_loss/2000))
            running_loss = 0.0

        training_losses.append(loss.item())
print('Finished Training')



plt.figure(figsize=(20,5))
plt.title("LOSS")
plt.plot(training_losses,label="LOSS")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

testroot = '/content/gdrive/My Drive/testing/'

batch_size = 32
# Number of GPUs available. Use 0 for CPU mode.

transform1 = transforms.Compose([transforms.Resize(image_size),
                                transforms.CenterCrop(image_size),
                                transforms.ToTensor(),
                                transforms.Normalize([0.485, 0.456, 0.406],
                                                    [0.229, 0.224, 0.225])])


testdataset = datasets.ImageFolder(root=testroot,transform=transform1)

testset = torch.utils.data.DataLoader(testdataset, batch_size=batch_size,
                                          shuffle=False, num_workers=workers)

print("Number of images in Test dataset = ",len(testdataset))

testsampledata = iter(testset)

testimages, testlabels = testsampledata.next()

print("Shape of the images",testimages.shape)
print("Shape of the labels",testlabels.shape)

fig = plt.figure(figsize=(15,20))
for i in np.arange(4):
    ax = fig.add_subplot(1,4, i+1, xticks = [], yticks = [])
    view_sample_image(testimages[i])
    ax.set_title(classes[testlabels[i]])

PATH = './cifar_net.pth'
torch.save(net.state_dict(), PATH)

net = Network()
net.load_state_dict(torch.load(PATH))

sample_outputs = net(testimages)
_, predicted = torch.max(sample_outputs, 1)

print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]
                              for j in range(4)))

correct = 0
total = 0
with torch.no_grad():
    for testdata in testset:
        images, labels = testdata
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on test images: %d %%' % (
    100 * correct / total))

